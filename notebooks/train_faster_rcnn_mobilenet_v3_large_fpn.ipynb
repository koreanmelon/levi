{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection.faster_rcnn import \\\n",
    "    FasterRCNN_MobileNet_V3_Large_FPN_Weights\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, scheduler):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    training_losses = []\n",
    "    num_correct = 0\n",
    "    for X, y in tqdm(dataloader, unit=\"batch\"):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Metrics\n",
    "        training_losses.append(loss.item())\n",
    "        num_correct += torch.sum(torch.ceil(pred.argmax(1)) == y).item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    return np.mean(training_losses), num_correct / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    num_correct = 0\n",
    "    test_losses = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_losses.append(loss_fn(pred, y).item())\n",
    "            num_correct += torch.sum(torch.ceil(pred.argmax(1)) == y).item()\n",
    "\n",
    "    test_loss = np.mean(test_losses)\n",
    "    test_acc = num_correct / size\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_names = COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "# this will help us create a different color for each class\n",
    "COLORS = np.random.uniform(0, 255, size=(len(coco_names), 3))\n",
    "\n",
    "\n",
    "def predict(image, model, device, detection_threshold):\n",
    "    # transform the image to tensor\n",
    "    image = transform(image).to(device)\n",
    "    image = image.unsqueeze(0)  # add a batch dimension\n",
    "    outputs = model(image)  # get the predictions on the image\n",
    "    print(outputs)\n",
    "    # print the results individually\n",
    "    # print(f\"BOXES: {outputs[0]['boxes']}\")\n",
    "    # print(f\"LABELS: {outputs[0]['labels']}\")\n",
    "    # print(f\"SCORES: {outputs[0]['scores']}\")\n",
    "    # get all the predicited class names\n",
    "    pred_classes = [coco_names[i] for i in outputs[0]['labels'].cpu().numpy()]\n",
    "    # get score for all the predicted objects\n",
    "    pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n",
    "    # get all the predicted bounding boxes\n",
    "    pred_bboxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
    "    # get boxes above the threshold score\n",
    "    boxes = pred_bboxes[pred_scores >= detection_threshold].astype(np.int32)\n",
    "    return boxes, pred_classes, outputs[0]['labels']\n",
    "\n",
    "\n",
    "def draw_boxes(boxes, classes, labels, image):\n",
    "    # read the image with OpenCV\n",
    "    image = cv2.cvtColor(np.asarray(image), cv2.COLOR_BGR2RGB)\n",
    "    for i, box in enumerate(boxes):\n",
    "        color = COLORS[labels[i]]\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (int(box[0]), int(box[1])),\n",
    "            (int(box[2]), int(box[3])),\n",
    "            color, 2\n",
    "        )\n",
    "        cv2.putText(image, classes[i], (int(box[0]), int(box[1]-5)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2,\n",
    "                    lineType=cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn()\n",
    "\n",
    "image = cv2.imread(\"./data/stop_sign.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "model.eval().to(device)\n",
    "boxes, classes, labels = predict(image, model, device, 0.8)\n",
    "image = draw_boxes(boxes, classes, labels, image)\n",
    "save_name = f\"out\"\n",
    "cv2.imwrite(f\"outputs/{save_name}.jpg\", image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "levi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
